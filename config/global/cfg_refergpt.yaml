# dataset info
dataset_path: "dataset/data/KITTI/training"
detections_path: "dataset/data/detections_casa"
llm_output_data_file: "dataset/data/updated_casa_llm_output_data"


save_path: 'evaluation/results/sha_key/data'
# tokenizer_model_path: "/media/diana/Elements/leandro/PhD/Open-Vocabulary/tzulio_eusipco/tokenizer_finetuned/T5-Large-finetuned"
# expression_path: "dataset/data/refer-kitti-v2/expression" #v2
expression_path: "dataset/data/refer-kitti-v1/expression" #v1
# gt_path: "dataset/data/refer-kitti-v2/labels_with_ids" #v2
gt_path: "dataset/data/refer-kitti-v1/labels_with_ids" #v1

dataset_type: "refer-kitti" #v1
# dataset_type: "refer-kitti-v2" #v2



# val [1,6,8,10,12,13,14,15,16,18,19]
# trainval [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
# test [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]
tracking_seqs:  [5, 11, 13]

# tracking type
# tracking_type: Car
tracking_type: Car

# KF parameters
state_func_covariance: 100
measure_func_covariance: 0.001
prediction_score_decay: 0.025
LiDAR_scanning_frequency: 10

# max prediction number of state function
max_prediction_num: 16
max_prediction_num_for_new_object: 6

# detection score threshold
input_score: -1.5
init_score: -1.5
update_score: -1.5
post_score: 1.6

# tracking latency (s)
# -1: global tracking
# 0.->500: online or near online tracking
latency: -1

query_tokenization: False

#
# VLM/LLM parameters
#
# vlm_model: Specifies which Vision-Language Model (VLM) to use for generating outputs (e.g., "llava", "gpt4").
# use_llm: If True, use the specified VLM to generate outputs on-the-fly. If False, use pre-saved/generated LLM outputs from disk.
# save_llm_output: If True and use_llm is also True, save the outputs generated by the VLM during this run for future use.
vlm_model: "gpt4"           # Vision-Language Model to use (e.g., "llava", "gpt4")
use_llm: False                # Use the VLM to generate outputs (True) or use pre-saved outputs (False)
save_llm_output: False       # Save generated VLM outputs if use_llm is True


online_query_tracking: False
similarity_threshold: -1
majority_voting_ratio: 0.4
distance_threshold: 150